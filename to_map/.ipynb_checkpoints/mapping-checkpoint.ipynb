{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jaro\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "from fuzzywuzzy import fuzz\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    def ld_nh(path):\n",
    "        for f in os.listdir(path):\n",
    "            if not f.startswith('.'):\n",
    "                yield f\n",
    "    return list (ld_nh(path))\n",
    "\n",
    "def show_county_data(county, data):\n",
    "    d = data[[c for c in data.columns if 'geo' not in c]].copy()\n",
    "    return d[d.county==county].sort_values(d.columns[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the native indexes for mapping, so don't reset or drop them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 6 rows found with unique loc_prec values. Overwriting prec_shp...\n",
      "> 2 with unique geometry rows share names! Adding indexes to names...\n",
      "  > PATRIOTS PARK (1/2)\n",
      "  > PATRIOTS PARK (2/2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>precinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>appling</td>\n",
       "      <td>1b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>appling</td>\n",
       "      <td>1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>appling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       county precinct\n",
       "1450  appling       1b\n",
       "1451  appling       1c\n",
       "1452  appling        2"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SHAPES DATA\n",
    "\n",
    "shapes = gp.read_file('electoral_precincts/2018Precincts.shp')\n",
    "shapes = shapes[list(shapes.columns[:4])+['geometry']]\n",
    "# rows where loc_prec contains a value not the same as prec_shp\n",
    "mismatch = np.where(((shapes['locality']+','+shapes['prec_shp']\n",
    "                  ).str.lower()!=shapes['loc_prec'].str.lower()))\n",
    "print('>', len(mismatch[0]), 'rows found with unique loc_prec values. Overwriting prec_shp...')\n",
    "# replace odd prec_shp values (they are duplicated in prec_elect)\n",
    "shapes.prec_elec = shapes.loc_prec.apply(lambda x: x.split(',')[1])\n",
    "shapes.drop('loc_prec', axis=1, inplace=True)\n",
    "\n",
    "# dna = Duplicate Named Area (areas with unique geometry that )\n",
    "dna = shapes[shapes.duplicated(['locality', 'prec_shp'])].copy()\n",
    "dup_idx = dna[dna.duplicated(['geometry'])].index\n",
    "dna.drop(dup_idx, inplace=True) # drop straight-up duplicates\n",
    "shapes.drop(dup_idx, inplace=True) # drop straight-up duplicates\n",
    "print('>', len(dna), 'with unique geometry rows share names! Adding indexes to names...')\n",
    "idxr = 1\n",
    "for d_idx in dna.index: # remainig rows have unique gemoetry\n",
    "    o_val = dna.loc[d_idx, 'prec_shp']\n",
    "    n_val = f'{o_val} ({idxr}/{len(dna)})'\n",
    "    shapes.loc[d_idx, 'prec_shp'] = n_val # assign back into shapes directly.\n",
    "    idxr += 1\n",
    "    print('  >', n_val)\n",
    "    \n",
    "# clean vals (force lowercase) and rename\n",
    "for c in shapes.columns[:3]:\n",
    "    shapes[c] = shapes[c].str.lower()\n",
    "shapes.rename(columns={'locality':'county'}, inplace=True)\n",
    "\n",
    "shapes[shapes.county=='appling'].sort_values('prec_shp').head(3)\n",
    "\n",
    "\n",
    "# OLD RUNOFF PARTICPATION DATA\n",
    "\n",
    "part = pd.read_csv('../recent_runoffs/2018_november_cleaned/all_precincts_participation.csv')\n",
    "part = part[list(part.columns[:3])]\n",
    "for c in part.columns: part[c] = part[c].str.lower()\n",
    "part.rename(columns={\n",
    "        'County':'county',\n",
    "        'PRECINCT ID': 'prec_id',\n",
    "        'PRECINCT DESCRIPTION': 'prec_desc'\n",
    "    }, inplace=True)\n",
    "\n",
    "part[part.county=='appling'].sort_values('prec_desc').head(3)\n",
    "\n",
    "\n",
    "# 2018 NOVEMBER RESULTS DATA\n",
    "\n",
    "res = pd.read_csv('../2020_november/all_precincts_joined/US Senate (Loeffler).csv')\n",
    "res = res[list(res.columns[:2])]\n",
    "res.rename(columns={k:k.lower() for k in res.columns}, inplace=True)\n",
    "for c in res.columns: res[c] = res[c].str.lower()\n",
    "    \n",
    "res[res.county=='appling'].sort_values('precinct').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual fixes - exact string replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE EXACT STRINGS in SHAPES DATA\n",
    "\n",
    "replace_strs = {\n",
    "    'hoggard mill': 'hoggards mill',\n",
    "    'south mill': 'south milledgeville',\n",
    "    'north mill': 'north milledgeville',\n",
    "    'bethlehem church - 211': 'bethlehem church',\n",
    "    'chattahoochee acvitity center': 'activity center' ,\n",
    "    'cjc': '#3 cjc',\n",
    "}\n",
    "for o, n in replace_strs.items():\n",
    "    for c in shapes.columns[:3]:\n",
    "        shapes[c] = shapes[c].str.replace(o, n)\n",
    "        \n",
    "# REPLACE EXACT STRINGS in PART DATA\n",
    "\n",
    "replace_strs = {\n",
    "    'austin \\(dun\\)': 'austin',\n",
    "    'avondale \\(avo\\)': 'avondale',\n",
    "    'lithonia \\(lit\\)': 'lithonia',\n",
    "    'woodward \\(bhavn\\)': 'woodward',\n",
    "    'fbc - flc': 'family life center',\n",
    "}\n",
    "for o, n in replace_strs.items():\n",
    "    for c in part.columns[:3]:\n",
    "        part[c] = part[c].str.replace(o, n)\n",
    "        \n",
    "# REPLACE EXACT STRINGS in RES DATA\n",
    "replace_strs = {\n",
    "    ' ':' '\n",
    "}\n",
    "for o, n in replace_strs.items():\n",
    "    for c in res.columns[:3]:\n",
    "        res[c] = res[c].str.replace(o, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## direct edits by iloc - warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RISKY â€” THESE MAY CHANGE!!\n",
    "part.loc[133, 'prec_desc'] = 'fairground'\n",
    "part.loc[358, 'prec_desc'] = 'eli whitney'\n",
    "part.loc[291, 'prec_desc'] = 'wilmington island presbyterian'\n",
    "part.loc[347, 'prec_desc'] = 'wilmington island united'\n",
    "\n",
    "res.loc[1136, 'precinct_id'] =  'bramlett elementary'\n",
    "res.loc[1137, 'precinct_id'] =  'westside middle'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specific county cleaning\n",
    "\n",
    "### strip numbers from barrow precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD COLUMN FOR PARSED PRECINCT IDs EXACT STRINGS\n",
    "county='barrow'\n",
    "barrow_idx = show_county_data(county, res).index\n",
    "barrow_ids = res.loc[barrow_idx, 'precinct'].apply(lambda x: ' '.join(re.findall('[A-Za-z]*', x)))\n",
    "res.loc[barrow_idx, 'precinct'] = barrow_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### de-code rockdale precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rockdale_p_map = {'BA': 'Barkside',\n",
    " 'BT': 'Bethel',\n",
    " 'CO': 'Conyers',\n",
    " 'FI': 'Fieldstone',\n",
    " 'FS': 'Flat Shoals',\n",
    " 'HC': 'Honey Creek',\n",
    " 'HI': 'High Tower',\n",
    " 'LA': 'The Lakes',\n",
    " 'LO': 'Lorraine',\n",
    " 'MA': 'Magnet',\n",
    " 'MI': 'Milestead',\n",
    " 'OT': 'Olde Town',\n",
    " 'RO': 'Rockdale',\n",
    " 'SM': 'Smyrna',\n",
    " 'SP': 'St. Pius',\n",
    " 'ST': 'Stanton'}\n",
    "\n",
    "def convert_rockdale(ab):\n",
    "    ab = ab.upper()\n",
    "    if ab in rockdale_p_map.keys():\n",
    "        return rockdale_p_map[ab].lower()\n",
    "    else:\n",
    "        return ab.lower()\n",
    "    \n",
    "rock_idx = part[part.county=='rockdale'].index\n",
    "\n",
    "part.loc[rock_idx, 'prec_id'] = part.loc[rock_idx, 'prec_id'].apply(convert_rockdale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix spalding leading zero numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "spald = shapes[shapes.county=='spalding'].index\n",
    "\n",
    "def convert_spald(n):\n",
    "    if len(n)<2:\n",
    "        return'0'+n\n",
    "    else:\n",
    "        return n\n",
    "\n",
    "shapes.loc[spald, 'prec_shp'] = shapes.loc[spald, 'prec_shp'].apply(convert_spald)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterate shape index objects, looking for data from `part` and `res`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS LOOP searches for matches across datasets using multiple columns\n",
    "# (precinct id, precinct, prec_elec, prec_id, precinct description)\n",
    "# ideally, a perfect match is found. always search within a matching county.\n",
    "# if no perfect match for a given search, try fuzzy or custom searching... \n",
    "\n",
    "def find_matches(l_df, r_df, l_comp_cols, r_comp_cols, p_groupby, min_score, testing=False):\n",
    "    match_hist = {} # to store the results and stats about matches\n",
    "    found = 0\n",
    "    if not testing:\n",
    "        iter_over = sorted(list(l_df[p_groupby].unique()))\n",
    "    else: iter_over=testing \n",
    "\n",
    "    for p_item in tqdm(iter_over):    \n",
    "        #   l = left data  |  r = right data\n",
    "\n",
    "        # isolate data in just item group for both dataframes...\n",
    "        l_group = l_df[l_df[p_groupby]==p_item] # geojson l_df data\n",
    "        r_group = r_df[r_df[p_groupby]==p_item] # r_df grouped by county\n",
    "\n",
    "        # for row in L_DATA data... (within this P_GROUP (ie COUNTY DATA)):\n",
    "        for l_idx in l_group.index: # iterate items objects in this group\n",
    "            l_row = l_group.loc[l_idx] \n",
    "\n",
    "            # to store results and break a search when a match is found\n",
    "            match_hist[l_idx] = 0\n",
    "\n",
    "            # search for PERFECT match across ALL COMPARISON COLUMNS:\n",
    "            # this assumes there are no duplicates because it breaks when a match is found\n",
    "\n",
    "        # PERFECT match search\n",
    "            # iterating SHAPE precinct name columns...\n",
    "            for l_compare in l_comp_cols: \n",
    "                if match_hist[l_idx]: break # break if perfect match found\n",
    "\n",
    "                if '_found' in l_compare or '_fuzz' in l_compare:\n",
    "                    continue # ignore found data column\n",
    "\n",
    "                l_val = l_row[l_compare] # SHAPE VALUE NAME\n",
    "\n",
    "                # for row in R_DATA data...\n",
    "                for r_idx in r_group.index: \n",
    "                    if match_hist[l_idx]: break # if search done, break this inner\n",
    "                    r_row = r_group.loc[r_idx]\n",
    "\n",
    "                    # ...compare against both possible precinct name columns\n",
    "                    for r_compare in r_comp_cols:\n",
    "                        if '_found' in r_compare or '_fuzz' in r_compare:\n",
    "                            continue # ignore found data column   \n",
    "                        r_val = r_row[r_compare]\n",
    "                        if l_val == r_val: # ***CHECK THE L==R VALUE EQUATION***\n",
    "                            meth = f'{l_compare} == {r_compare}'\n",
    "                            \n",
    "                            match_hist[l_idx] = {\n",
    "                                'match_idx': r_idx, 'method': meth }\n",
    "                            \n",
    "                            l_df.loc[l_idx, 'r_idx'] = r_idx\n",
    "                            l_df.loc[l_idx, 'r_mthd'] = meth\n",
    "                            \n",
    "                            break \n",
    "\n",
    "            # end l_row search if perfect match found\n",
    "            if match_hist[l_idx]: continue\n",
    "\n",
    "\n",
    "        # FUZZY match search (if needed)\n",
    "            # minimum score to beat from function input\n",
    "            best_score = min_score-.01\n",
    "            if p_item=='fulton':\n",
    "                best_score = .94\n",
    "        \n",
    "            for l_compare in l_comp_cols:  # iterating shape columns\n",
    "                if '_found' in l_compare or '_fuzz' in l_compare:\n",
    "                    continue  # ignore found data column\n",
    "\n",
    "                # no internal break, search ALL possible scores\n",
    "                #if '_found' in l_compare: continue # ignore found data column\n",
    "\n",
    "                l_val = l_row[l_compare] # SHAPE VALUE NAME\n",
    "\n",
    "\n",
    "                for r_idx in r_group.index: # iterate R_DF rows\n",
    "                    \n",
    "                    if r_idx in l_df['r_idx'].values: continue # already assigned!\n",
    "                        \n",
    "                    # DONT break\n",
    "                    r_row = r_group.loc[r_idx]\n",
    "                    # search ALL possible FUZZY MATCHES...\n",
    "                    for r_compare in r_row.index[1:]:\n",
    "                        \n",
    "                        if '_found' in r_compare or '_fuzz' in r_compare:\n",
    "                            continue # ignore results column(s)\n",
    "                            \n",
    "                        if best_score==1: break  # not going to find anything better!\n",
    "\n",
    "                        r_val = r_row[r_compare] # PART VALUE NAME\n",
    "\n",
    "                        # jaro score\n",
    "                        f_score = jaro.jaro_metric(str(l_val), str(r_val))\n",
    "\n",
    "                        if f_score > best_score: # new best score\n",
    "                            best_score = f_score\n",
    "                            f_str = str(round(f_score, 2)).split('.')[1]\n",
    "                            meth = f\"(F.{f_str}) {l_compare} = {r_compare}\"\n",
    "                            match_hist[l_idx] = {\n",
    "                                'match_idx': r_idx,\n",
    "                                'method': meth }\n",
    "                                                    \n",
    "                            l_df.loc[l_idx, 'r_idx'] = r_idx\n",
    "                            l_df.loc[l_idx, 'r_mthd'] = meth\n",
    "                            l_df.loc[l_idx, 'r_fuzz'] = r_val\n",
    "                            # dont break, search all. \n",
    "\n",
    "                            \n",
    "    method_vals = []\n",
    "    for val in match_hist.values():\n",
    "        try: method_vals.append(val['method'])\n",
    "        except: pass\n",
    "    match_method_counts = {c: method_vals.count(c) for c in set(method_vals)}\n",
    "    pct_found = sum(match_method_counts.values()) / len(l_df) # l_df with a match in both datasets\n",
    "    pct_found = round(100*pct_found, 2)\n",
    "    print(f\"{sum(match_method_counts.values())}/{len(l_df)} precincts found exact match in PART data: {pct_found}%\")\n",
    "    return l_df, r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94a16ba8aee4ee3813969a8f61872f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=159.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2628/2655 precincts found exact match in PART data: 98.98%\n"
     ]
    }
   ],
   "source": [
    "l_df = shapes\n",
    "l_comp_cols = list(shapes.columns[1:3])\n",
    "r_df = part\n",
    "r_comp_cols = list(part.columns[1:])\n",
    "p_groupby = 'county'\n",
    "min_score = .7 # init to beat\n",
    "testing = False#['fulton']\n",
    "  \n",
    "l_df, r_df = find_matches(l_df, r_df, l_comp_cols, r_comp_cols, p_groupby, min_score, testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join all parsed counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaker = 0\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "counties = sorted(list(l_df.county.unique()))\n",
    "for county in counties:\n",
    "    lc_data = show_county_data(county, l_df)\n",
    "    rc_data = show_county_data(county, r_df)\n",
    "\n",
    "    rc_data = rc_data.rename(columns={c:'R_'+c for c in rc_data.columns})\n",
    "    lc_data = lc_data.rename(columns={c:'L_'+c for c in lc_data.columns})\n",
    "    #lc_data.drop('L_county', axis=1, inplace=True)\n",
    "\n",
    "    c_data = pd.merge(rc_data, lc_data, left_index=True, right_on='L_r_idx', how='outer')\n",
    "    \n",
    "    data = pd.concat([data, c_data])\n",
    "    \n",
    "data['county'] = data['R_county'].fillna(data['L_county']).copy()\n",
    "data = data.sort_values('R_prec_id').sort_values('R_county')\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.drop(columns=['R_county', 'L_county'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_prec_id</th>\n",
       "      <th>R_prec_desc</th>\n",
       "      <th>L_prec_shp</th>\n",
       "      <th>L_prec_elec</th>\n",
       "      <th>L_r_idx</th>\n",
       "      <th>L_r_mthd</th>\n",
       "      <th>L_r_fuzz</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fort stewart military reserve (no voters)</td>\n",
       "      <td>fort stewart military reserve (no voters)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fort pulaski national monument (no voters</td>\n",
       "      <td>fort pulaski national monument (no voters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chatham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fort benning military reservation (no vot</td>\n",
       "      <td>fort benning military reservation (no vot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chattahoochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03p1b</td>\n",
       "      <td>03p1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08f2</td>\n",
       "      <td>08f2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>12e2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121sc14b</td>\n",
       "      <td>121sc14b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ap01e</td>\n",
       "      <td>ap01e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ap12d</td>\n",
       "      <td>ap12d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ch04b</td>\n",
       "      <td>ch04b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cp052</td>\n",
       "      <td>cp052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cp06b</td>\n",
       "      <td>cp06b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cp07a</td>\n",
       "      <td>cp07a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fc01</td>\n",
       "      <td>fc01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fc02</td>\n",
       "      <td>fc02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fc03</td>\n",
       "      <td>fc03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rw11b</td>\n",
       "      <td>rw11b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rw22b</td>\n",
       "      <td>rw22b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sc07b</td>\n",
       "      <td>sc07b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sc08a</td>\n",
       "      <td>sc08a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sc21a</td>\n",
       "      <td>sc21a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sc29b</td>\n",
       "      <td>sc29b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ss29b</td>\n",
       "      <td>ss29b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uc01c</td>\n",
       "      <td>uc01c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uc033</td>\n",
       "      <td>uc033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uc035</td>\n",
       "      <td>uc035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fort benning military reservation (no vot</td>\n",
       "      <td>fort benning military reservation (no vot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>muscogee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R_prec_id R_prec_desc                                 L_prec_shp  \\\n",
       "2855       NaN         NaN  fort stewart military reserve (no voters)   \n",
       "2856       NaN         NaN  fort pulaski national monument (no voters   \n",
       "2857       NaN         NaN  fort benning military reservation (no vot   \n",
       "2858       NaN         NaN                                      03p1b   \n",
       "2859       NaN         NaN                                       08f2   \n",
       "2860       NaN         NaN                                       1200   \n",
       "2861       NaN         NaN                                   121sc14b   \n",
       "2862       NaN         NaN                                      ap01e   \n",
       "2863       NaN         NaN                                      ap12d   \n",
       "2864       NaN         NaN                                      ch04b   \n",
       "2865       NaN         NaN                                      cp052   \n",
       "2866       NaN         NaN                                      cp06b   \n",
       "2867       NaN         NaN                                      cp07a   \n",
       "2868       NaN         NaN                                       fc01   \n",
       "2869       NaN         NaN                                       fc02   \n",
       "2870       NaN         NaN                                       fc03   \n",
       "2871       NaN         NaN                                      rw11b   \n",
       "2872       NaN         NaN                                      rw22b   \n",
       "2873       NaN         NaN                                      sc07b   \n",
       "2874       NaN         NaN                                      sc08a   \n",
       "2875       NaN         NaN                                      sc21a   \n",
       "2876       NaN         NaN                                      sc29b   \n",
       "2877       NaN         NaN                                      ss29b   \n",
       "2878       NaN         NaN                                      uc01c   \n",
       "2879       NaN         NaN                                      uc033   \n",
       "2880       NaN         NaN                                      uc035   \n",
       "2881       NaN         NaN  fort benning military reservation (no vot   \n",
       "\n",
       "                                    L_prec_elec  L_r_idx L_r_mthd L_r_fuzz  \\\n",
       "2855  fort stewart military reserve (no voters)      NaN      NaN      NaN   \n",
       "2856  fort pulaski national monument (no voters      NaN      NaN      NaN   \n",
       "2857  fort benning military reservation (no vot      NaN      NaN      NaN   \n",
       "2858                                      03p1b      NaN      NaN      NaN   \n",
       "2859                                       08f2      NaN      NaN      NaN   \n",
       "2860                                       12e2      NaN      NaN      NaN   \n",
       "2861                                   121sc14b      NaN      NaN      NaN   \n",
       "2862                                      ap01e      NaN      NaN      NaN   \n",
       "2863                                      ap12d      NaN      NaN      NaN   \n",
       "2864                                      ch04b      NaN      NaN      NaN   \n",
       "2865                                      cp052      NaN      NaN      NaN   \n",
       "2866                                      cp06b      NaN      NaN      NaN   \n",
       "2867                                      cp07a      NaN      NaN      NaN   \n",
       "2868                                       fc01      NaN      NaN      NaN   \n",
       "2869                                       fc02      NaN      NaN      NaN   \n",
       "2870                                       fc03      NaN      NaN      NaN   \n",
       "2871                                      rw11b      NaN      NaN      NaN   \n",
       "2872                                      rw22b      NaN      NaN      NaN   \n",
       "2873                                      sc07b      NaN      NaN      NaN   \n",
       "2874                                      sc08a      NaN      NaN      NaN   \n",
       "2875                                      sc21a      NaN      NaN      NaN   \n",
       "2876                                      sc29b      NaN      NaN      NaN   \n",
       "2877                                      ss29b      NaN      NaN      NaN   \n",
       "2878                                      uc01c      NaN      NaN      NaN   \n",
       "2879                                      uc033      NaN      NaN      NaN   \n",
       "2880                                      uc035      NaN      NaN      NaN   \n",
       "2881  fort benning military reservation (no vot      NaN      NaN      NaN   \n",
       "\n",
       "             county  \n",
       "2855          bryan  \n",
       "2856        chatham  \n",
       "2857  chattahoochee  \n",
       "2858         fulton  \n",
       "2859         fulton  \n",
       "2860         fulton  \n",
       "2861         fulton  \n",
       "2862         fulton  \n",
       "2863         fulton  \n",
       "2864         fulton  \n",
       "2865         fulton  \n",
       "2866         fulton  \n",
       "2867         fulton  \n",
       "2868         fulton  \n",
       "2869         fulton  \n",
       "2870         fulton  \n",
       "2871         fulton  \n",
       "2872         fulton  \n",
       "2873         fulton  \n",
       "2874         fulton  \n",
       "2875         fulton  \n",
       "2876         fulton  \n",
       "2877         fulton  \n",
       "2878         fulton  \n",
       "2879         fulton  \n",
       "2880         fulton  \n",
       "2881       muscogee  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.L_r_idx.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in merged.index:\n",
    "    \n",
    "    row_data = merged.loc[row]\n",
    "    descript = [\n",
    "        str(row_data['PRECINCT ID']),\n",
    "        str(row_data['PRECINCT DESCRIPTION']),\n",
    "        str(row_data['prec_shp']),\n",
    "        str(row_data['prec_elec']),\n",
    "    ]\n",
    "    \n",
    "    # pick longest, break ties manually\n",
    "    longest = max([len(x) for x in descript])\n",
    "    if len(descript[2])==longest:\n",
    "        out = descript[2]\n",
    "    elif len(descript[3])==longest:\n",
    "        out = descript[3]\n",
    "    elif len(descript[0])==longest:\n",
    "        out = descript[0]\n",
    "    elif len(descript[1])==longest:\n",
    "        out = descript[1]\n",
    "        \n",
    "    if row == 2866:\n",
    "        print(descript, longest, out)\n",
    "        \n",
    "    out = ' '.join([w.capitalize() for w in out.split()])\n",
    "    \n",
    "    merged.loc[row, 'best_name'] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.geometry = merged.simplify(.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from branca.colormap import linear\n",
    "colormap = linear.GnBu_06.scale(min(merged['CALC_CHANGE_PARTICIPATION']),\n",
    "                                  max(merged['CALC_CHANGE_PARTICIPATION']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from branca.colormap import linear\n",
    "\n",
    "\n",
    "if 'Election - 2018' in election:\n",
    "    fname = 'Nov-Dec 2018'\n",
    "    colormap = linear.GnBu_06.scale(-50, -25)\n",
    "elif 'Primary - 2018' in election:\n",
    "    fname = 'May-Jul 2018'\n",
    "    colormap = linear.GnBu_06.scale(-25, 0)\n",
    "elif 'Primary - 2016' in election:\n",
    "    colormap = linear.GnBu_06.scale(-25, 0)\n",
    "    fname = 'May-Jun 2016'\n",
    "\n",
    "def get_color(amt):\n",
    "    try: return colormap(amt)\n",
    "    except: return '#808080'\n",
    "    \n",
    "def get_opacity(amt):\n",
    "    try:\n",
    "        amt>5\n",
    "        return .7\n",
    "    except: return 0\n",
    "                                  \n",
    "m = folium.Map(location=[32.719440, -83.453088],\n",
    "zoom_start = 7, tiles='cartodbpositron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.INIT_PCT_voted_TOTAL_VOTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_function = lambda x: {\n",
    "    'fillColor': get_color(x['properties']['CALC_CHANGE_PARTICIPATION']),\n",
    "    'color': 'black',\n",
    "    'weight': .1,\n",
    "    'opacity': 0.5,\n",
    "    'fillOpacity': get_opacity(x['properties']['CALC_CHANGE_PARTICIPATION'])\n",
    "}\n",
    "\n",
    "merged.CALC_CHANGE_PARTICIPATION.fillna('Error / no data for this precinct')\n",
    "\n",
    "folium.GeoJson(\n",
    "    merged,\n",
    "    style_function=style_function,\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=['best_name', 'locality', 'INIT_PCT_voted_TOTAL_VOTERS', 'RUNOFF_PCT_voted_TOTAL_VOTERS'],\n",
    "        aliases=['Precinct:', 'County:', 'Initial participation:', 'Run-off participation:'],\n",
    "        #localize=True,\n",
    "    )\n",
    ").add_to(m)\n",
    "\n",
    "colormap.add_to(m)\n",
    "colormap.caption = f'Voting rates PCT CHANGE from initial to run-off elections ({fname})'\n",
    "\n",
    "colormap.add_to(m);\n",
    "\n",
    "\n",
    "m\n",
    "#m.save(f'{fname}_Precinct_RunoffDeltas.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
